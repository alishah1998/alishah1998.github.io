[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Lab 2: Google Trends vs Web Scrapping with R",
    "section": "",
    "text": "Google Trend vs Web Scrapping with R\nGoogle trend has a much friendlier user interface making it much easier to use. In this example I performed a google trend search analyzing the interest over time for Donald Trump and Joe Biden. To perform this search, I went onto trends.google.com/trends/explore. In the box “Add a search term”, I typed in “Donald Trump” and press the enter key. A “+ Compare” button will appear to the right of the previous term where I typed in “Joe Biden”. I then changed the region into United States.\nFollowing these steps will prompt google to display an Interest over time graph and a compared breakdown by subregion. The second graph allows the user to change the subregion into metro and city.\n\n\n\n\n\n\n\n\n\n\nGoogle trends allows you to download the CSV file that contains the data used to create these graphs. Having this data allows you to generate your own graphs using tools such as Excel. For example:\n\n\n\n\n\nThis is a column table that makes it easier to compare search results from specific days of the year. This feature allows for the user to gain a lot of insight with relative ease.\nAnother way to gather this information Is to web scrape the data using R. To do this you will need to install the package “gtrendsR”. After installing the package, we need to write a bit of code\nplot(gtrends(c(“Donald Trump”, “Joe Biden”), geo = “US”, time = “today 12-m”))\ndata(“countries”)\nThis line of code is essentially doing this search for us and creating a plot to compare the search results. The resulting graph will look like this:\n\n\n\n\n\nThe benefit of using this method is the speed you can receive visualizes. You can change the category to search, geography, and timespan by changing the code to your desired results. This has its advantages when wanting to perform niche searches that are not available with Google Trends. For example, Google Trends will not allow the user to select multiple countries at once. By scrapping the data, the user can compare search results from multiple terms in multiple locations. For example, I can compare Donald Trump (US), Donald Trump (MX), Joe Biden (US), and Joe Biden (MX).\nThis extra freedom comes with a more difficult user interface that may be more difficult for users to learn when compared to Google Trends But having that extra freedom when conducting web scrapping can allow for the user to gain much more insights then they could with Google Trends."
  },
  {
    "objectID": "Assignement1.html",
    "href": "Assignement1.html",
    "title": "Lab 1: Understanding Qualitrics",
    "section": "",
    "text": "Analyzed survey link: Qualtrics Survey\n\nHow is the survey structured?\n\nThis is a crowd sourcing internet survey.\n\nWhat is the questionnaire composed of?\n\nThe first question is for consent, the second is a Bipolar scale since it has multiple questions scaling from Strongly disagree – strongly agree., followed by multiple choice questions. There are also some dropdown questions that are used to gather data about the participants.\n\nHow are the questions ordered?\n\nThe first question (Q1) is giving the participants information about the survey and gaining consent from the participant. The next question (Q2) is a Bipolar scale seeing the participants attitude towards movies. They specifically question the participants about attitudes towards renting movies, different film ratings, social attitude towards movies, and software’s that controls explicit content.\nThe next question (Q3) is multiple choice, single answer regarding the hardware the participant may be willing to purchase.\nQ4 – Q6 are multiple-choice single answer questions regarding the participant’s interest in a software that controls explicit content and how much the participant believes it would cost and how much they are willing to pay for it.\nQ7 – Q10 are multiple-choice single answer questions regarding the participant’s preference over how they would purchase this software.\nQ11 – Q13 are multiple-choice single answer questions regarding how the participants choose to watch movies and how much they typically spend on movies.\nQ14 – Q18 are all demographic questions with Q14 and Q15 being multiple choice drop-down format while Q16-Q18 are regular multiple choice single answer question’s. \n\nWhat can be done to improve respondent’s experience?\n\nThe survey could be more mobile friendly. Users having to scroll from side to side can be frustrating and possibly accidentally cause the user to forget a question. Getting rid of the bipolar matrix scale and replacing it with a multiple-choice bipolar matrix would be easier for the user. The survey also repeats questions that were already asked, getting rid of the repeat questions could save time for the user."
  },
  {
    "objectID": "Assignement3_textanalysis.html",
    "href": "Assignement3_textanalysis.html",
    "title": "Lab 3: Quanteda text analysis",
    "section": "",
    "text": "Biden-Xi text analysis\nThe provided information comprises Twitter text data that has been extracted into R code. It encompasses numerous observations, each tied to articles posted on Twitter featuring discussions about Xi Jinping and Joe Biden. The data points are categorized by quotes and retweets, and alongside the article titles, the names of the users who tweeted about these articles are also presented. This dataset is extensive, comprising well over 1,000 observations. In essence, it delineates the relationships between Joe Biden and Xi Jinping, offering articles that compare their actions towards each other and explore aspects of international relations. words like “Freedom”, “Patriot”, and “people’. This make sense as both of these speeches have similar context and are meant to help the leader gain support\nUS presidential inaugural speeches\nThis data set encompasses observations pertaining to the inaugural speeches of U.S. presidents, spanning from President Eisenhower to President Trump. The visual representations illustrate the frequency of specific words used in these speeches, such as “people,” “American,” and “communist.” It is reasonable to expect an increased usage of the term “communist” during the Nixon and Reagan eras, given the heightened prominence of the Red Scare during those periods. However, a noteworthy observation is the relatively limited mention of the word “American” in the data set, particularly in speeches by earlier presidents. Presidents also seem to employ the term “American” more frequently than prior presidents\n\n.\nWhat is Wordfish\n“Wordfish” refers to the method of predicting the positioning of documents by examining the frequency of word usage. This technique, commonly implemented in R, involves organizing data according to the prevalence of words, as exemplified in the previous analysis of inaugural speech data."
  },
  {
    "objectID": "Assignement4_YouTubeanalysis.html",
    "href": "Assignement4_YouTubeanalysis.html",
    "title": "Lab 5: YouTube Analysis",
    "section": "",
    "text": "Analyzing the stats and comments\nCNN’s content statistics indicate a notable increase in views and comments following the initiation of Hamas’s attack on Israel. This heightened traffic has facilitated the dissemination of specific narratives surrounding the issue. User engagement with the channel experienced a rise after Hamas’s attack, and there has been a subsequent increase in comments as well. Since these comments are available as text data, analytical tools for text data can be employed to assess the general sentiment of the comments and identify any political “bias” exhibited by users. By analyzing the comments, it becomes possible to determine whether there is a prevailing “pro-Israel” perspective on the violence.\nQuanteda can be effectively employed to analyze text data extracted from YouTube comments. Initially, after obtaining the data, a “client ID” can be generated to systematically organize all the text data. For example, if the focus is on retrieving text data related to “Israel protest,” a corpus can be crafted to encompass those specific characteristics. Subsequently, a summary of the text data can be drawn, and this summary can be saved as a data frame for further analysis. Utilizing packages such as “ggplot2” enables the visualization and in-depth analysis of the data."
  },
  {
    "objectID": "Assignement6_textmining.html",
    "href": "Assignement6_textmining.html",
    "title": "Lab 6: Text Mining",
    "section": "",
    "text": "You can scrape entire pdf files and data by webscrapping. The process of webscrapping can be done using packages like beautifulsoup on python or tidyverse if using R. Both of these methods require you to go into the HTML data on the website and find the corresponding data to the put into the code. One thing to keep in mind is that pulling data from a website very quickly could be seen as an attack, so it is important to add a loop to delay the downloading let the system know that this is not a cyber attack"
  },
  {
    "objectID": "Assignement7_govdata.html",
    "href": "Assignement7_govdata.html",
    "title": "Lab 7: Government Data and Parallel Processing",
    "section": "",
    "text": "Government Data Code\n\nParallel Processing\n\nPlanning for Storage:\nplanning for the storage is incredibly important as running this without proper storage can cause the program to fail and fill up the entire hard-drive. This is especially true when you are downloading terabits of data at a time. We use packages like tic tac to also slow the time between downloads to not overload the server. Data management is incredibly important as well. using packages like ggplot can help with visualizing the data and making it look amazing.\nOrganizing data:\nOrganizing data is just as important as downloading it. When you are downloading terabits of data as a time, keeping organize is essential to ensure easy access to the files. Data can be easily organized in R by putting the files into a csv file.\nUsing Arrow method:\nArrow is a way of storing data that’s super efficient for analytics. Instead of arranging data in rows, it organizes it in columns, which helps with things like making queries faster. Arrow uses a special way of turning data into a series of 1s and 0s that other programs easily understand. It works well with many data types Arrow is often used with tools like Apache Spark and Pandas to make data processing faster and more straightforward."
  },
  {
    "objectID": "Assignement8_spatialdata.html",
    "href": "Assignement8_spatialdata.html",
    "title": "Lab 8: Spatial Data",
    "section": "",
    "text": "After following the steps to receive the key for the census data we were able to find the median age of of the united state by each state and using functions like mapview gives us a graphic of the data and lables it as such.\n\nFor this one the lighter version of blue are considered younger than those that are closer to green.\nWe continue onto spatial data where we use packages like tidycensus to access the key and tmaps to import a map of Texas. The next graphic is used to make an interactive map of Texas where you are able to zoom into each county, This is going to be very useful when attempting the find information about each county, The UI also makes it easier for quick look-ups.\n\nComparison between the 2010 and 2020 data reveals some similarities. Notably, there appears to be a decrease in the population of individuals aged 38 to 43 in the northwestern part of the country. Conversely, the concentration of older individuals along the east coast remains relatively consistent. In general, the distribution pattern remains similar, with individuals aged 35 and under being most prevalent in Texas, Alabama, and Alaska in both years. This makes sense that many of the eastern coast states have older average as they are typically more economically sound compared to many other states."
  },
  {
    "objectID": "index.html#my-data-science-journey",
    "href": "index.html#my-data-science-journey",
    "title": "Welcome",
    "section": "My Data Science Journey:",
    "text": "My Data Science Journey:\nCurrently master student studying Social Data Analytics and Research which focus on applying Data Science into social science. I have a professional certification in Data Analytics Essentials from University of Texas, which focuses on using SQL, Tableau, Excel, and Python to gain business insights using big data. I am actively seeking an internship in the field of Data Analytics, Business Analytics, Business Intelligence, or Data Science.\n\nThrough my previous work experiences, I have developed the ability to work efficiently in a fast-paced environment, collect accurate and reliable data, maintain well-organized records, communicate professionally both verbally and in writing, and establish positive relationships with clients and other professionals. I am excited to bring my skills and experience to a new opportunity and make a valuable contribution to the organization.\nLets connect:\nLinkedIn\nEmail: alishah1998@hotmail.com\nPhone: 469-877-9009"
  },
  {
    "objectID": "Lab1.html",
    "href": "Lab1.html",
    "title": "Lab 1: Understanding Qualitrics",
    "section": "",
    "text": "Analyzed survey link: Qualtrics Survey\n\nHow is the survey structured?\n\nThis is a crowd sourcing internet survey.\n\nWhat is the questionnaire composed of?\n\nThe first question is for consent, the second is a Bipolar scale since it has multiple questions scaling from Strongly disagree – strongly agree., followed by multiple choice questions. There are also some dropdown questions that are used to gather data about the participants.\n\nHow are the questions ordered?\n\nThe first question (Q1) is giving the participants information about the survey and gaining consent from the participant. The next question (Q2) is a Bipolar scale seeing the participants attitude towards movies. They specifically question the participants about attitudes towards renting movies, different film ratings, social attitude towards movies, and software’s that controls explicit content.\nThe next question (Q3) is multiple choice, single answer regarding the hardware the participant may be willing to purchase.\nQ4 – Q6 are multiple-choice single answer questions regarding the participant’s interest in a software that controls explicit content and how much the participant believes it would cost and how much they are willing to pay for it.\nQ7 – Q10 are multiple-choice single answer questions regarding the participant’s preference over how they would purchase this software.\nQ11 – Q13 are multiple-choice single answer questions regarding how the participants choose to watch movies and how much they typically spend on movies.\nQ14 – Q18 are all demographic questions with Q14 and Q15 being multiple choice drop-down format while Q16-Q18 are regular multiple choice single answer question’s. \n\nWhat can be done to improve respondent’s experience?\n\nThe survey could be more mobile friendly. Users having to scroll from side to side can be frustrating and possibly accidentally cause the user to forget a question. Getting rid of the bipolar matrix scale and replacing it with a multiple-choice bipolar matrix would be easier for the user. The survey also repeats questions that were already asked, getting rid of the repeat questions could save time for the user."
  },
  {
    "objectID": "personal projects.html",
    "href": "personal projects.html",
    "title": "Personal Projects",
    "section": "",
    "text": "Video Game Sales Insight and Analysis:\nThis Project involved creating an interactive dashboard that helps employees to monitor KPIs of the health of a subscription-based sales model. Skill used includes Dashboarding, Data Filters, Parameters for measurements, Data modification and transformation using calculation, quick table calculations, creating appropriate charts, and creating a Tableau Public Interface.\nFood-Hub Order Analysis:\nThis project involved analyzing data obtained from a food delivery app. Employed missing value treatments to clean the data, provided a comprehensive statistical summary with visual representations, and made business recommendations based on the findings. The skills utilized in this project include Variable Identification, Univariate and Bi-Variate analysis, as well as proficiency in Python programming.\nStress Related to Transitioning from Online to In-person During the COVID19 Pandemic:\nThis is an IRB approved research project conducted at the University of Texas at Dallas, involving an online survey administered to 100 students to measure their perceived stress before and after transitioning from online to in-person classes. The data collected, stored, and analyzed using Excel and ANNOV. Data was visualized in Excel and poster was produced in MS PowerPoint. The study was presented at a UT Dallas research fair. The study’s methodologies, procedure, data, limitations, and conclusions were documented in APA format."
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "469-877-9009 | alishah1998@hotmail.com | LinkedIn Profile\nEducation/Certifications\nM.S | Social Data Analytics and Research | The University of Texas at Dallas| Currently Enrolled\n\nRelevant skills: Data collection and Production, Knowledge Mining, Machine Learning, Advanced Statistics, Research Design, Quantitative Analysis, Algorithmic Modeling, Data Analysis, Academic writing, API’s, search-based web scraping, data mining, Visualization, big data management, Data Science, Information management, Surveys\n\nB.S | Psychology | The University of Texas at Dallas | May 2022\n\nRelated coursework: Research Design & Analysis, Experimental Projects in Psychology, Statistics for Life Sciences, Organic Chemistry Lab, General Chemistry Lab, Mechanics Lab, Electromagnetism and Waves Lab, Computer Science Lab, Organizational Behavior\n\nProfessional Certificate | Data Analytics Essentials | University of Texas | April 2023\n\nRelated Coursework: Data Analytics Foundations with MS Excel, Data Analytics with SQL, Data-driven Insights using Python, Creative Storytelling with Tableau\n\nTechnical Skills\n\nProgramming Languages: Python, RStudio, SQL, Excel, Qualtrics, C++, stata, sas\nData Visualization Tools: Tableau, MS Excel, PowerBI\nData & Research Skills: Experimental Design, Data Collection, Quantitative Analysis, Database Management, API’s, Web Scrapping, Survey Building, Predictive Modeling, Machine Learning, Data Mining\nAnalysis Tools/Libraries: Pandas, NumPy, Matplotlib, gtrendsR,\nOther Skills: Verbal and Written Communication, Time Management Skills, Interpersonal Skills, Customer Service. Medical Terminology, Leadership, Presentation Skills,\n\nWork Experience\nResearch Analyst Intern | Texas Division of Emergency Management | Current Position\n- Provide final product reports by each operational period.\n- Web Scrapping using API’s on social medias platforms (Facebook, Twitter, YouTube, Reddit)\n- Emergency Database Management\n- Monitor online sources for relative information to include in reports.\n- Generate reports to aid the response to and recovery from disasters.\n- Research/Investigate individuals or groups, upon request.\n- Compile analytical data and generate visualizations for reports.\n- Relay urgent information to command staff to preserve life and property.\n- Provide operational period/shift activity summaries for sitreps.\n- Identify and report needs solicited by an affected community and individuals.\n- Utilize Microsoft Teams Channels to communicate and collect data for reports.\n- Log time and activities in the Intern Activity Log, survey.\nResearch Analyst Assistant | Healthy Development Project | August 2021\n\nA research laboratory at the University of Texas at Dallas led by the head of the psychology department Dr. Shayla Holub. Collected data of over 500 family eating habits and inputting this data into MS Excel. I would record key behaviors from the child input the information into. Visualized the results using MS Excel and MS PowerPoint. Created and presented a research poster presentation to thousands during public research fairs.\n\nSale Specialist | Apple | Current Position\n\nDiscover customers’ needs, then follow up with the right solutions. Guided and advised customers and helped set up their new products. Generated over $100,000 of revenue within 7 months, experience managing money transactions over $8000."
  },
  {
    "objectID": "Resume.html#ali-m.-shah",
    "href": "Resume.html#ali-m.-shah",
    "title": "Resume",
    "section": "",
    "text": "469-877-9009 | alishah1998@hotmail.com | LinkedIn Profile\nEducation/Certifications\nM.S | Social Data Analytics and Research | The University of Texas at Dallas| Currently Enrolled\n\nRelevant skills: Data collection and Production, Knowledge Mining, Machine Learning, Advanced Statistics, Research Design, Quantitative Analysis, Algorithmic Modeling, Data Analysis, Academic writing, API’s, search-based web scraping, data mining, Visualization, big data management, Data Science, Information management, Surveys\n\nB.S | Psychology | The University of Texas at Dallas | May 2022\n\nRelated coursework: Research Design & Analysis, Experimental Projects in Psychology, Statistics for Life Sciences, Organic Chemistry Lab, General Chemistry Lab, Mechanics Lab, Electromagnetism and Waves Lab, Computer Science Lab, Organizational Behavior\n\nProfessional Certificate | Data Analytics Essentials | University of Texas | April 2023\n\nRelated Coursework: Data Analytics Foundations with MS Excel, Data Analytics with SQL, Data-driven Insights using Python, Creative Storytelling with Tableau\n\nTechnical Skills\n\nProgramming Languages: Python, RStudio, SQL, Excel, Qualtrics, C++, stata, sas\nData Visualization Tools: Tableau, MS Excel, PowerBI\nData & Research Skills: Experimental Design, Data Collection, Quantitative Analysis, Database Management, API’s, Web Scrapping, Survey Building, Predictive Modeling, Machine Learning, Data Mining\nAnalysis Tools/Libraries: Pandas, NumPy, Matplotlib, gtrendsR,\nOther Skills: Verbal and Written Communication, Time Management Skills, Interpersonal Skills, Customer Service. Medical Terminology, Leadership, Presentation Skills,\n\nWork Experience\nResearch Analyst Intern | Texas Division of Emergency Management | Current Position\n- Provide final product reports by each operational period.\n- Web Scrapping using API’s on social medias platforms (Facebook, Twitter, YouTube, Reddit)\n- Emergency Database Management\n- Monitor online sources for relative information to include in reports.\n- Generate reports to aid the response to and recovery from disasters.\n- Research/Investigate individuals or groups, upon request.\n- Compile analytical data and generate visualizations for reports.\n- Relay urgent information to command staff to preserve life and property.\n- Provide operational period/shift activity summaries for sitreps.\n- Identify and report needs solicited by an affected community and individuals.\n- Utilize Microsoft Teams Channels to communicate and collect data for reports.\n- Log time and activities in the Intern Activity Log, survey.\nResearch Analyst Assistant | Healthy Development Project | August 2021\n\nA research laboratory at the University of Texas at Dallas led by the head of the psychology department Dr. Shayla Holub. Collected data of over 500 family eating habits and inputting this data into MS Excel. I would record key behaviors from the child input the information into. Visualized the results using MS Excel and MS PowerPoint. Created and presented a research poster presentation to thousands during public research fairs.\n\nSale Specialist | Apple | Current Position\n\nDiscover customers’ needs, then follow up with the right solutions. Guided and advised customers and helped set up their new products. Generated over $100,000 of revenue within 7 months, experience managing money transactions over $8000."
  },
  {
    "objectID": "Survey.html",
    "href": "Survey.html",
    "title": "Lab 4: Survey",
    "section": "",
    "text": "Qualtrics Survey"
  }
]